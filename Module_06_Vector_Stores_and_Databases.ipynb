{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Vector Stores & Databases\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "By the end of this module, you will:\n",
    "- Understand vector database architecture and why traditional databases aren't suitable for similarity search\n",
    "- Compare different vector store options (local vs cloud, open-source vs commercial)\n",
    "- Implement CRUD operations for vectors with metadata\n",
    "- Design effective metadata schemas for filtering and organization\n",
    "- Benchmark and optimize vector database performance\n",
    "\n",
    "## ðŸ“š Key Concepts\n",
    "\n",
    "### Why Vector Databases?\n",
    "\n",
    "Traditional databases excel at exact matches but struggle with **similarity search**:\n",
    "\n",
    "```sql\n",
    "-- Traditional SQL: Exact match\n",
    "SELECT * FROM documents WHERE title = 'Machine Learning';\n",
    "\n",
    "-- What we need: Similarity search\n",
    "SELECT * FROM documents WHERE embedding SIMILAR TO query_embedding;\n",
    "```\n",
    "\n",
    "#### ðŸš« Traditional Database Limitations\n",
    "1. **No built-in similarity search**: SQL doesn't understand \"semantic closeness\"\n",
    "2. **Inefficient for high-dimensional data**: Traditional indexes don't work well for 1000+ dimensions\n",
    "3. **Slow approximate search**: Need specialized algorithms like HNSW, not B-trees\n",
    "4. **Poor scalability**: Linear scan becomes prohibitive with millions of vectors\n",
    "\n",
    "#### âœ… Vector Database Advantages\n",
    "1. **Approximate Nearest Neighbor (ANN)**: Fast similarity search with controllable accuracy\n",
    "2. **Optimized indexing**: HNSW, IVF, LSH algorithms designed for high-dimensional vectors\n",
    "3. **Metadata filtering**: Combine vector similarity with traditional filters\n",
    "4. **Horizontal scaling**: Built for production workloads with millions/billions of vectors\n",
    "\n",
    "### 2025 Vector Database Landscape ðŸ†\n",
    "\n",
    "| Database | Query Latency | Cost | Best For |\n",
    "|----------|---------------|------|---------|\n",
    "| **Pinecone** | 23ms p95 | High | Enterprise, turnkey scale |\n",
    "| **Qdrant** | ~30ms | Low | Complex filters, self-hosted |\n",
    "| **Weaviate** | 34ms p95 | Medium | OSS flexibility, GraphQL |\n",
    "| **Milvus** | Lowest | Variable | GPU acceleration |\n",
    "| **Chroma** | 20ms p50 | Free | Fast prototyping |\n",
    "\n",
    "### Database Categories\n",
    "\n",
    "#### ðŸ  Local/Embedded Options\n",
    "- **Chroma**: SQLite-based, perfect for development\n",
    "- **FAISS**: Meta's library, CPU/GPU optimized\n",
    "- **Hnswlib**: Pure HNSW implementation, very fast\n",
    "\n",
    "#### â˜ï¸ Cloud/Managed Options\n",
    "- **Pinecone**: Fully managed, highest performance\n",
    "- **Weaviate**: Open-source with cloud hosting\n",
    "- **Qdrant**: Rust-based, excellent cost/performance\n",
    "\n",
    "#### ðŸ—„ï¸ Traditional DB Extensions\n",
    "- **pgvector**: PostgreSQL extension\n",
    "- **Redis**: In-memory vector search\n",
    "- **Elasticsearch**: Dense vector search support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Setup\n",
    "Let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q chromadb qdrant-client faiss-cpu sentence-transformers numpy pandas matplotlib seaborn\n",
    "!pip install -q langchain langchain-chroma langchain-community openai python-dotenv\n",
    "# Note: For Pinecone, add: pinecone-client\n",
    "# Note: For Weaviate, add: weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import json\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector database imports\n",
    "import chromadb\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, Range\n",
    "import faiss\n",
    "\n",
    "# Embedding models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n",
    "print(f\"ðŸ“… Today's date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Exercise 1: Traditional Database vs Vector Database\n",
    "\n",
    "Let's demonstrate why traditional databases struggle with similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents\n",
    "sample_documents = [\n",
    "    \"Machine learning algorithms can learn patterns from data\",\n",
    "    \"Deep learning uses neural networks with multiple layers\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Computer vision enables machines to interpret images\",\n",
    "    \"Reinforcement learning trains agents through rewards\",\n",
    "    \"The weather today is sunny and warm\",\n",
    "    \"I love cooking pasta with tomato sauce\",\n",
    "    \"Basketball is a popular sport worldwide\",\n",
    "    \"Python is a versatile programming language\",\n",
    "    \"Data science combines statistics and programming\"\n",
    "]\n",
    "\n",
    "# Create embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(sample_documents)\n",
    "\n",
    "print(f\"ðŸ“Š Created {len(sample_documents)} documents\")\n",
    "print(f\"ðŸ”¢ Embedding dimensions: {embeddings.shape[1]}\")\n",
    "print(f\"ðŸ’¾ Total embedding size: {embeddings.nbytes:,} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_keyword_search(query: str, documents: List[str]) -> List[Tuple[int, str]]:\n",
    "    \"\"\"Simulate traditional keyword-based search\"\"\"\n",
    "    query_words = set(query.lower().split())\n",
    "    results = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        doc_words = set(doc.lower().split())\n",
    "        # Simple keyword overlap score\n",
    "        overlap = len(query_words.intersection(doc_words))\n",
    "        if overlap > 0:\n",
    "            results.append((i, doc, overlap))\n",
    "    \n",
    "    # Sort by overlap score\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [(idx, doc) for idx, doc, _ in results[:3]]\n",
    "\n",
    "def vector_similarity_search(query: str, documents: List[str], embeddings: np.ndarray) -> List[Tuple[int, str, float]]:\n",
    "    \"\"\"Vector-based similarity search\"\"\"\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarities = np.dot(embeddings, query_embedding) / (\n",
    "        np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "    )\n",
    "    \n",
    "    # Get top 3 results\n",
    "    top_indices = np.argsort(similarities)[::-1][:3]\n",
    "    \n",
    "    return [(idx, documents[idx], similarities[idx]) for idx in top_indices]\n",
    "\n",
    "# Test both approaches\n",
    "test_queries = [\n",
    "    \"artificial intelligence and neural networks\",\n",
    "    \"understanding human language\",\n",
    "    \"programming and data analysis\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ” SEARCH COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nâ“ Query: '{query}'\")\n",
    "    \n",
    "    # Traditional search\n",
    "    print(\"\\nðŸ—‚ï¸ Traditional Keyword Search:\")\n",
    "    traditional_results = traditional_keyword_search(query, sample_documents)\n",
    "    if traditional_results:\n",
    "        for i, (idx, doc) in enumerate(traditional_results):\n",
    "            print(f\"   {i+1}. {doc}\")\n",
    "    else:\n",
    "        print(\"   âŒ No results found (no keyword matches)\")\n",
    "    \n",
    "    # Vector search\n",
    "    print(\"\\nðŸ§  Vector Similarity Search:\")\n",
    "    vector_results = vector_similarity_search(query, sample_documents, embeddings)\n",
    "    for i, (idx, doc, score) in enumerate(vector_results):\n",
    "        print(f\"   {i+1}. {doc} (similarity: {score:.3f})\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Exercise 2: Vector Database Architecture Comparison\n",
    "\n",
    "Let's set up and compare different vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDBBenchmark:\n",
    "    \"\"\"Benchmark different vector database implementations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def setup_chroma(self, documents: List[str], embeddings: np.ndarray) -> chromadb.Collection:\n",
    "        \"\"\"Set up Chroma vector database\"\"\"\n",
    "        client = chromadb.Client()\n",
    "        \n",
    "        # Create or get collection\n",
    "        try:\n",
    "            collection = client.create_collection(\n",
    "                name=\"test_collection\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "        except:\n",
    "            client.delete_collection(\"test_collection\")\n",
    "            collection = client.create_collection(\n",
    "                name=\"test_collection\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "        \n",
    "        # Add documents\n",
    "        collection.add(\n",
    "            embeddings=embeddings.tolist(),\n",
    "            documents=documents,\n",
    "            ids=[f\"doc_{i}\" for i in range(len(documents))],\n",
    "            metadatas=[{\"source\": \"sample\", \"index\": i} for i in range(len(documents))]\n",
    "        )\n",
    "        \n",
    "        return collection\n",
    "    \n",
    "    def setup_qdrant_memory(self, documents: List[str], embeddings: np.ndarray) -> QdrantClient:\n",
    "        \"\"\"Set up Qdrant in-memory database\"\"\"\n",
    "        client = QdrantClient(\":memory:\")\n",
    "        \n",
    "        # Create collection\n",
    "        client.create_collection(\n",
    "            collection_name=\"test_collection\",\n",
    "            vectors_config=VectorParams(\n",
    "                size=embeddings.shape[1],\n",
    "                distance=Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add points\n",
    "        points = [\n",
    "            PointStruct(\n",
    "                id=i,\n",
    "                vector=embeddings[i].tolist(),\n",
    "                payload={\n",
    "                    \"text\": documents[i],\n",
    "                    \"source\": \"sample\",\n",
    "                    \"index\": i\n",
    "                }\n",
    "            )\n",
    "            for i in range(len(documents))\n",
    "        ]\n",
    "        \n",
    "        client.upsert(\n",
    "            collection_name=\"test_collection\",\n",
    "            points=points\n",
    "        )\n",
    "        \n",
    "        return client\n",
    "    \n",
    "    def setup_faiss(self, embeddings: np.ndarray) -> faiss.IndexFlatIP:\n",
    "        \"\"\"Set up FAISS index\"\"\"\n",
    "        # Normalize embeddings for cosine similarity\n",
    "        normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        \n",
    "        # Create index\n",
    "        index = faiss.IndexFlatIP(embeddings.shape[1])  # Inner product for cosine similarity\n",
    "        index.add(normalized_embeddings.astype('float32'))\n",
    "        \n",
    "        return index, normalized_embeddings\n",
    "    \n",
    "    def benchmark_search(self, query: str, databases: Dict[str, Any], documents: List[str]) -> Dict[str, Dict]:\n",
    "        \"\"\"Benchmark search performance across databases\"\"\"\n",
    "        query_embedding = embedding_model.encode([query])[0]\n",
    "        results = {}\n",
    "        \n",
    "        # Chroma search\n",
    "        if 'chroma' in databases:\n",
    "            start_time = time.time()\n",
    "            chroma_results = databases['chroma'].query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=3\n",
    "            )\n",
    "            chroma_time = time.time() - start_time\n",
    "            results['chroma'] = {\n",
    "                'time': chroma_time * 1000,  # Convert to ms\n",
    "                'results': list(zip(chroma_results['documents'][0], chroma_results['distances'][0]))\n",
    "            }\n",
    "        \n",
    "        # Qdrant search\n",
    "        if 'qdrant' in databases:\n",
    "            start_time = time.time()\n",
    "            qdrant_results = databases['qdrant'].search(\n",
    "                collection_name=\"test_collection\",\n",
    "                query_vector=query_embedding.tolist(),\n",
    "                limit=3\n",
    "            )\n",
    "            qdrant_time = time.time() - start_time\n",
    "            results['qdrant'] = {\n",
    "                'time': qdrant_time * 1000,\n",
    "                'results': [(point.payload['text'], point.score) for point in qdrant_results]\n",
    "            }\n",
    "        \n",
    "        # FAISS search\n",
    "        if 'faiss' in databases:\n",
    "            faiss_index, normalized_embeddings = databases['faiss']\n",
    "            normalized_query = query_embedding / np.linalg.norm(query_embedding)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            scores, indices = faiss_index.search(\n",
    "                normalized_query.reshape(1, -1).astype('float32'), 3\n",
    "            )\n",
    "            faiss_time = time.time() - start_time\n",
    "            results['faiss'] = {\n",
    "                'time': faiss_time * 1000,\n",
    "                'results': [(documents[idx], score) for idx, score in zip(indices[0], scores[0])]\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize benchmark\n",
    "benchmark = VectorDBBenchmark()\n",
    "\n",
    "print(\"ðŸ—ï¸ Setting up vector databases...\")\n",
    "\n",
    "# Set up databases\n",
    "databases = {}\n",
    "\n",
    "print(\"   Setting up Chroma...\")\n",
    "databases['chroma'] = benchmark.setup_chroma(sample_documents, embeddings)\n",
    "\n",
    "print(\"   Setting up Qdrant (in-memory)...\")\n",
    "databases['qdrant'] = benchmark.setup_qdrant_memory(sample_documents, embeddings)\n",
    "\n",
    "print(\"   Setting up FAISS...\")\n",
    "databases['faiss'] = benchmark.setup_faiss(embeddings)\n",
    "\n",
    "print(\"âœ… All databases ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark search performance\n",
    "test_query = \"machine learning and AI algorithms\"\n",
    "\n",
    "print(f\"ðŸš€ VECTOR DATABASE BENCHMARK\")\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "benchmark_results = benchmark.benchmark_search(test_query, databases, sample_documents)\n",
    "\n",
    "# Display results\n",
    "performance_data = []\n",
    "\n",
    "for db_name, result in benchmark_results.items():\n",
    "    print(f\"\\nðŸ—„ï¸ {db_name.upper()} Results:\")\n",
    "    print(f\"   â±ï¸ Query time: {result['time']:.2f}ms\")\n",
    "    print(\"   ðŸ“„ Top results:\")\n",
    "    \n",
    "    for i, (doc, score) in enumerate(result['results']):\n",
    "        print(f\"      {i+1}. {doc[:50]}... (score: {score:.3f})\")\n",
    "    \n",
    "    performance_data.append({\n",
    "        'Database': db_name.title(),\n",
    "        'Query Time (ms)': result['time'],\n",
    "        'Top Score': result['results'][0][1] if result['results'] else 0\n",
    "    })\n",
    "\n",
    "# Create performance comparison\n",
    "perf_df = pd.DataFrame(performance_data)\n",
    "print(f\"\\nðŸ“Š Performance Summary:\")\n",
    "print(perf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Query time comparison\n",
    "bars1 = ax1.bar(perf_df['Database'], perf_df['Query Time (ms)'], \n",
    "                color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax1.set_title('Query Time Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Time (milliseconds)')\n",
    "ax1.set_xlabel('Vector Database')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars1, perf_df['Query Time (ms)']):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.2f}ms', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Top score comparison\n",
    "bars2 = ax2.bar(perf_df['Database'], perf_df['Top Score'], \n",
    "                color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax2.set_title('Similarity Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Similarity Score')\n",
    "ax2.set_xlabel('Vector Database')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars2, perf_df['Top Score']):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Observations:\")\n",
    "print(\"- FAISS typically offers the fastest query times for pure vector similarity\")\n",
    "print(\"- Chroma provides a good balance of speed and ease of use for development\")\n",
    "print(\"- Qdrant offers advanced filtering capabilities with competitive performance\")\n",
    "print(\"- All databases should return similar similarity scores for the same query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Exercise 3: CRUD Operations and Metadata Management\n",
    "\n",
    "Let's implement comprehensive CRUD (Create, Read, Update, Delete) operations with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedVectorStore:\n",
    "    \"\"\"Advanced vector store with comprehensive CRUD operations\"\"\"\n",
    "    \n",
    "    def __init__(self, db_type=\"chroma\"):\n",
    "        self.db_type = db_type\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        if db_type == \"chroma\":\n",
    "            self.client = chromadb.Client()\n",
    "            try:\n",
    "                self.collection = self.client.create_collection(\n",
    "                    name=\"advanced_collection\",\n",
    "                    metadata={\"hnsw:space\": \"cosine\"}\n",
    "                )\n",
    "            except:\n",
    "                self.client.delete_collection(\"advanced_collection\")\n",
    "                self.collection = self.client.create_collection(\n",
    "                    name=\"advanced_collection\",\n",
    "                    metadata={\"hnsw:space\": \"cosine\"}\n",
    "                )\n",
    "        elif db_type == \"qdrant\":\n",
    "            self.client = QdrantClient(\":memory:\")\n",
    "            self.collection_name = \"advanced_collection\"\n",
    "            self.client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "            )\n",
    "    \n",
    "    def create_document(self, doc_id: str, text: str, metadata: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Create a new document with embedding and metadata\"\"\"\n",
    "        try:\n",
    "            embedding = self.embedding_model.encode([text])[0]\n",
    "            \n",
    "            if self.db_type == \"chroma\":\n",
    "                self.collection.add(\n",
    "                    embeddings=[embedding.tolist()],\n",
    "                    documents=[text],\n",
    "                    ids=[doc_id],\n",
    "                    metadatas=[metadata]\n",
    "                )\n",
    "            elif self.db_type == \"qdrant\":\n",
    "                point = PointStruct(\n",
    "                    id=doc_id,\n",
    "                    vector=embedding.tolist(),\n",
    "                    payload={**metadata, \"text\": text}\n",
    "                )\n",
    "                self.client.upsert(\n",
    "                    collection_name=self.collection_name,\n",
    "                    points=[point]\n",
    "                )\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating document {doc_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def read_document(self, doc_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Read a specific document by ID\"\"\"\n",
    "        try:\n",
    "            if self.db_type == \"chroma\":\n",
    "                result = self.collection.get(ids=[doc_id])\n",
    "                if result['ids']:\n",
    "                    return {\n",
    "                        'id': result['ids'][0],\n",
    "                        'text': result['documents'][0],\n",
    "                        'metadata': result['metadatas'][0],\n",
    "                        'embedding': result['embeddings'][0] if result['embeddings'] else None\n",
    "                    }\n",
    "            elif self.db_type == \"qdrant\":\n",
    "                result = self.client.retrieve(\n",
    "                    collection_name=self.collection_name,\n",
    "                    ids=[doc_id],\n",
    "                    with_payload=True,\n",
    "                    with_vectors=True\n",
    "                )\n",
    "                if result:\n",
    "                    point = result[0]\n",
    "                    return {\n",
    "                        'id': point.id,\n",
    "                        'text': point.payload.get('text'),\n",
    "                        'metadata': {k: v for k, v in point.payload.items() if k != 'text'},\n",
    "                        'embedding': point.vector\n",
    "                    }\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading document {doc_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def update_document(self, doc_id: str, text: str = None, metadata: Dict[str, Any] = None) -> bool:\n",
    "        \"\"\"Update an existing document\"\"\"\n",
    "        try:\n",
    "            # For updates, we need to recreate the document\n",
    "            if text is not None:\n",
    "                current_doc = self.read_document(doc_id)\n",
    "                if current_doc:\n",
    "                    updated_metadata = current_doc['metadata'].copy()\n",
    "                    if metadata:\n",
    "                        updated_metadata.update(metadata)\n",
    "                    \n",
    "                    # Delete and recreate\n",
    "                    self.delete_document(doc_id)\n",
    "                    return self.create_document(doc_id, text, updated_metadata)\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating document {doc_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def delete_document(self, doc_id: str) -> bool:\n",
    "        \"\"\"Delete a document by ID\"\"\"\n",
    "        try:\n",
    "            if self.db_type == \"chroma\":\n",
    "                self.collection.delete(ids=[doc_id])\n",
    "            elif self.db_type == \"qdrant\":\n",
    "                self.client.delete(\n",
    "                    collection_name=self.collection_name,\n",
    "                    points_selector=[doc_id]\n",
    "                )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting document {doc_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_with_filters(self, query: str, filters: Dict[str, Any] = None, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search with metadata filtering\"\"\"\n",
    "        try:\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "            \n",
    "            if self.db_type == \"chroma\":\n",
    "                where_clause = filters if filters else None\n",
    "                results = self.collection.query(\n",
    "                    query_embeddings=[query_embedding.tolist()],\n",
    "                    n_results=top_k,\n",
    "                    where=where_clause\n",
    "                )\n",
    "                \n",
    "                return [\n",
    "                    {\n",
    "                        'id': results['ids'][0][i],\n",
    "                        'text': results['documents'][0][i],\n",
    "                        'metadata': results['metadatas'][0][i],\n",
    "                        'score': 1 - results['distances'][0][i]  # Convert distance to similarity\n",
    "                    }\n",
    "                    for i in range(len(results['ids'][0]))\n",
    "                ]\n",
    "            \n",
    "            elif self.db_type == \"qdrant\":\n",
    "                # Convert filters to Qdrant format\n",
    "                qdrant_filter = None\n",
    "                if filters:\n",
    "                    conditions = []\n",
    "                    for key, value in filters.items():\n",
    "                        if isinstance(value, (int, float)):\n",
    "                            conditions.append(FieldCondition(key=key, range=Range(gte=value, lte=value)))\n",
    "                        else:\n",
    "                            conditions.append(FieldCondition(key=key, match={\"value\": value}))\n",
    "                    qdrant_filter = Filter(must=conditions)\n",
    "                \n",
    "                results = self.client.search(\n",
    "                    collection_name=self.collection_name,\n",
    "                    query_vector=query_embedding.tolist(),\n",
    "                    limit=top_k,\n",
    "                    query_filter=qdrant_filter\n",
    "                )\n",
    "                \n",
    "                return [\n",
    "                    {\n",
    "                        'id': point.id,\n",
    "                        'text': point.payload.get('text'),\n",
    "                        'metadata': {k: v for k, v in point.payload.items() if k != 'text'},\n",
    "                        'score': point.score\n",
    "                    }\n",
    "                    for point in results\n",
    "                ]\n",
    "            \n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error in filtered search: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about the collection\"\"\"\n",
    "        try:\n",
    "            if self.db_type == \"chroma\":\n",
    "                count = self.collection.count()\n",
    "                return {\n",
    "                    'total_documents': count,\n",
    "                    'database_type': 'Chroma'\n",
    "                }\n",
    "            elif self.db_type == \"qdrant\":\n",
    "                info = self.client.get_collection(self.collection_name)\n",
    "                return {\n",
    "                    'total_documents': info.points_count,\n",
    "                    'database_type': 'Qdrant',\n",
    "                    'vector_size': info.config.params.vectors.size,\n",
    "                    'distance_metric': info.config.params.vectors.distance\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stats: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Initialize advanced vector store\n",
    "print(\"ðŸ—ï¸ Initializing Advanced Vector Store...\")\n",
    "vector_store = AdvancedVectorStore(db_type=\"chroma\")\n",
    "print(\"âœ… Advanced Vector Store ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents with rich metadata\n",
    "sample_documents_with_metadata = [\n",
    "    {\n",
    "        \"id\": \"ml_001\",\n",
    "        \"text\": \"Machine learning algorithms can automatically learn patterns from historical data without being explicitly programmed.\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"machine_learning\",\n",
    "            \"difficulty\": \"beginner\",\n",
    "            \"topic\": \"algorithms\",\n",
    "            \"word_count\": 14,\n",
    "            \"author\": \"AI_Expert\",\n",
    "            \"date\": \"2025-01-01\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"dl_001\",\n",
    "        \"text\": \"Deep learning uses neural networks with multiple hidden layers to model complex patterns in data.\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"deep_learning\",\n",
    "            \"difficulty\": \"intermediate\",\n",
    "            \"topic\": \"neural_networks\",\n",
    "            \"word_count\": 15,\n",
    "            \"author\": \"DL_Researcher\",\n",
    "            \"date\": \"2025-01-02\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"nlp_001\",\n",
    "        \"text\": \"Natural language processing enables computers to understand, interpret, and generate human language.\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"nlp\",\n",
    "            \"difficulty\": \"intermediate\",\n",
    "            \"topic\": \"language_understanding\",\n",
    "            \"word_count\": 13,\n",
    "            \"author\": \"NLP_Specialist\",\n",
    "            \"date\": \"2025-01-03\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"cv_001\",\n",
    "        \"text\": \"Computer vision algorithms analyze and interpret visual information from images and videos.\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"computer_vision\",\n",
    "            \"difficulty\": \"advanced\",\n",
    "            \"topic\": \"image_processing\",\n",
    "            \"word_count\": 12,\n",
    "            \"author\": \"CV_Engineer\",\n",
    "            \"date\": \"2025-01-04\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"rl_001\",\n",
    "        \"text\": \"Reinforcement learning trains agents to make decisions through trial and error using reward signals.\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"reinforcement_learning\",\n",
    "            \"difficulty\": \"advanced\",\n",
    "            \"topic\": \"decision_making\",\n",
    "            \"word_count\": 14,\n",
    "            \"author\": \"RL_Expert\",\n",
    "            \"date\": \"2025-01-05\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸ“ CRUD OPERATIONS DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# CREATE: Add documents\n",
    "print(\"\\nâž• CREATE Operation:\")\n",
    "for doc in sample_documents_with_metadata:\n",
    "    success = vector_store.create_document(doc[\"id\"], doc[\"text\"], doc[\"metadata\"])\n",
    "    print(f\"   Created {doc['id']}: {'âœ…' if success else 'âŒ'}\")\n",
    "\n",
    "# READ: Retrieve specific documents\n",
    "print(\"\\nðŸ“– READ Operation:\")\n",
    "retrieved_doc = vector_store.read_document(\"ml_001\")\n",
    "if retrieved_doc:\n",
    "    print(f\"   Retrieved: {retrieved_doc['id']}\")\n",
    "    print(f\"   Text: {retrieved_doc['text'][:50]}...\")\n",
    "    print(f\"   Category: {retrieved_doc['metadata']['category']}\")\n",
    "else:\n",
    "    print(\"   âŒ Document not found\")\n",
    "\n",
    "# Collection stats\n",
    "stats = vector_store.get_collection_stats()\n",
    "print(f\"\\nðŸ“Š Collection Stats: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced search with metadata filtering\n",
    "print(\"\\nðŸ” ADVANCED SEARCH WITH FILTERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Search without filters\n",
    "print(\"\\n1. General Search (no filters):\")\n",
    "results = vector_store.search_with_filters(\"learning algorithms\", top_k=3)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"   {i+1}. {result['text'][:60]}... (score: {result['score']:.3f})\")\n",
    "    print(f\"       Category: {result['metadata']['category']}, Difficulty: {result['metadata']['difficulty']}\")\n",
    "\n",
    "# Search with category filter\n",
    "print(\"\\n2. Filtered Search (category = 'deep_learning'):\")\n",
    "filtered_results = vector_store.search_with_filters(\n",
    "    \"neural networks\",\n",
    "    filters={\"category\": \"deep_learning\"},\n",
    "    top_k=3\n",
    ")\n",
    "for i, result in enumerate(filtered_results):\n",
    "    print(f\"   {i+1}. {result['text'][:60]}... (score: {result['score']:.3f})\")\n",
    "    print(f\"       Category: {result['metadata']['category']}\")\n",
    "\n",
    "# Search with difficulty filter\n",
    "print(\"\\n3. Filtered Search (difficulty = 'beginner'):\")\n",
    "beginner_results = vector_store.search_with_filters(\n",
    "    \"machine learning\",\n",
    "    filters={\"difficulty\": \"beginner\"},\n",
    "    top_k=3\n",
    ")\n",
    "for i, result in enumerate(beginner_results):\n",
    "    print(f\"   {i+1}. {result['text'][:60]}... (score: {result['score']:.3f})\")\n",
    "    print(f\"       Difficulty: {result['metadata']['difficulty']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE and DELETE operations\n",
    "print(\"\\nðŸ”„ UPDATE Operation:\")\n",
    "updated_text = \"Machine learning algorithms use statistical methods to automatically learn complex patterns from large datasets.\"\n",
    "update_success = vector_store.update_document(\n",
    "    \"ml_001\", \n",
    "    text=updated_text, \n",
    "    metadata={\"difficulty\": \"intermediate\", \"updated\": True}\n",
    ")\n",
    "print(f\"   Updated ml_001: {'âœ…' if update_success else 'âŒ'}\")\n",
    "\n",
    "# Verify update\n",
    "updated_doc = vector_store.read_document(\"ml_001\")\n",
    "if updated_doc:\n",
    "    print(f\"   New text: {updated_doc['text'][:50]}...\")\n",
    "    print(f\"   New difficulty: {updated_doc['metadata']['difficulty']}\")\n",
    "    print(f\"   Updated flag: {updated_doc['metadata'].get('updated', False)}\")\n",
    "\n",
    "print(\"\\nâŒ DELETE Operation:\")\n",
    "delete_success = vector_store.delete_document(\"cv_001\")\n",
    "print(f\"   Deleted cv_001: {'âœ…' if delete_success else 'âŒ'}\")\n",
    "\n",
    "# Verify deletion\n",
    "deleted_doc = vector_store.read_document(\"cv_001\")\n",
    "print(f\"   Document still exists: {'âŒ No' if deleted_doc is None else 'âœ… Yes'}\")\n",
    "\n",
    "# Final collection stats\n",
    "final_stats = vector_store.get_collection_stats()\n",
    "print(f\"\\nðŸ“Š Final Collection Stats: {final_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽï¸ Exercise 4: Performance Optimization and Scaling\n",
    "\n",
    "Let's explore performance optimization techniques for vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceOptimizer:\n",
    "    \"\"\"Performance optimization and benchmarking for vector databases\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.results = []\n",
    "    \n",
    "    def generate_synthetic_data(self, num_docs: int) -> Tuple[List[str], np.ndarray]:\n",
    "        \"\"\"Generate synthetic documents for performance testing\"\"\"\n",
    "        topics = [\n",
    "            \"machine learning\", \"deep learning\", \"natural language processing\",\n",
    "            \"computer vision\", \"data science\", \"artificial intelligence\",\n",
    "            \"neural networks\", \"reinforcement learning\", \"robotics\",\n",
    "            \"big data\", \"cloud computing\", \"cybersecurity\"\n",
    "        ]\n",
    "        \n",
    "        documents = []\n",
    "        for i in range(num_docs):\n",
    "            topic = topics[i % len(topics)]\n",
    "            doc = f\"This is document {i} about {topic} and its applications in modern technology. \"\n",
    "            doc += f\"It covers various aspects of {topic} including implementation details and best practices.\"\n",
    "            documents.append(doc)\n",
    "        \n",
    "        print(f\"Generating embeddings for {num_docs} documents...\")\n",
    "        embeddings = self.embedding_model.encode(documents, show_progress_bar=True)\n",
    "        \n",
    "        return documents, embeddings\n",
    "    \n",
    "    def benchmark_insertion(self, database_configs: Dict[str, Any], documents: List[str], embeddings: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Benchmark insertion performance\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for db_name, config in database_configs.items():\n",
    "            print(f\"\\nBenchmarking {db_name} insertion...\")\n",
    "            \n",
    "            if db_name == \"chroma\":\n",
    "                start_time = time.time()\n",
    "                \n",
    "                client = chromadb.Client()\n",
    "                try:\n",
    "                    collection = client.create_collection(\n",
    "                        name=f\"perf_test_{db_name}\",\n",
    "                        metadata={\"hnsw:space\": \"cosine\"}\n",
    "                    )\n",
    "                except:\n",
    "                    client.delete_collection(f\"perf_test_{db_name}\")\n",
    "                    collection = client.create_collection(\n",
    "                        name=f\"perf_test_{db_name}\",\n",
    "                        metadata={\"hnsw:space\": \"cosine\"}\n",
    "                    )\n",
    "                \n",
    "                # Batch insertion\n",
    "                batch_size = config.get('batch_size', 100)\n",
    "                for i in range(0, len(documents), batch_size):\n",
    "                    batch_docs = documents[i:i+batch_size]\n",
    "                    batch_embeddings = embeddings[i:i+batch_size]\n",
    "                    batch_ids = [f\"doc_{j}\" for j in range(i, min(i+batch_size, len(documents)))]\n",
    "                    batch_metadata = [{\"index\": j, \"batch\": i//batch_size} for j in range(i, min(i+batch_size, len(documents)))]\n",
    "                    \n",
    "                    collection.add(\n",
    "                        embeddings=batch_embeddings.tolist(),\n",
    "                        documents=batch_docs,\n",
    "                        ids=batch_ids,\n",
    "                        metadatas=batch_metadata\n",
    "                    )\n",
    "                \n",
    "                insertion_time = time.time() - start_time\n",
    "                results[db_name] = insertion_time\n",
    "            \n",
    "            elif db_name == \"qdrant\":\n",
    "                start_time = time.time()\n",
    "                \n",
    "                client = QdrantClient(\":memory:\")\n",
    "                collection_name = f\"perf_test_{db_name}\"\n",
    "                \n",
    "                client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(size=embeddings.shape[1], distance=Distance.COSINE)\n",
    "                )\n",
    "                \n",
    "                # Batch insertion\n",
    "                batch_size = config.get('batch_size', 100)\n",
    "                for i in range(0, len(documents), batch_size):\n",
    "                    batch_docs = documents[i:i+batch_size]\n",
    "                    batch_embeddings = embeddings[i:i+batch_size]\n",
    "                    \n",
    "                    points = [\n",
    "                        PointStruct(\n",
    "                            id=i+j,\n",
    "                            vector=batch_embeddings[j].tolist(),\n",
    "                            payload={\n",
    "                                \"text\": batch_docs[j],\n",
    "                                \"index\": i+j,\n",
    "                                \"batch\": i//batch_size\n",
    "                            }\n",
    "                        )\n",
    "                        for j in range(len(batch_docs))\n",
    "                    ]\n",
    "                    \n",
    "                    client.upsert(collection_name=collection_name, points=points)\n",
    "                \n",
    "                insertion_time = time.time() - start_time\n",
    "                results[db_name] = insertion_time\n",
    "            \n",
    "            elif db_name == \"faiss\":\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Normalize for cosine similarity\n",
    "                normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "                \n",
    "                # Create and populate index\n",
    "                index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "                index.add(normalized_embeddings.astype('float32'))\n",
    "                \n",
    "                insertion_time = time.time() - start_time\n",
    "                results[db_name] = insertion_time\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def benchmark_query_performance(self, num_queries: int = 100, num_docs: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"Comprehensive query performance benchmark\"\"\"\n",
    "        print(f\"\\nðŸŽï¸ PERFORMANCE BENCHMARK\")\n",
    "        print(f\"Documents: {num_docs}, Queries: {num_queries}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Generate test data\n",
    "        documents, embeddings = self.generate_synthetic_data(num_docs)\n",
    "        \n",
    "        # Database configurations\n",
    "        configs = {\n",
    "            \"chroma\": {\"batch_size\": 100},\n",
    "            \"qdrant\": {\"batch_size\": 100},\n",
    "            \"faiss\": {\"batch_size\": 1000}\n",
    "        }\n",
    "        \n",
    "        # Benchmark insertion\n",
    "        print(\"\\nBenchmarking insertion performance...\")\n",
    "        insertion_times = self.benchmark_insertion(configs, documents, embeddings)\n",
    "        \n",
    "        # Generate test queries\n",
    "        query_texts = [\n",
    "            \"machine learning algorithms\", \"deep neural networks\", \"data processing\",\n",
    "            \"artificial intelligence\", \"computer vision tasks\", \"natural language\"\n",
    "        ]\n",
    "        \n",
    "        test_queries = [query_texts[i % len(query_texts)] for i in range(num_queries)]\n",
    "        query_embeddings = self.embedding_model.encode(test_queries)\n",
    "        \n",
    "        # Benchmark query performance\n",
    "        print(\"\\nBenchmarking query performance...\")\n",
    "        \n",
    "        performance_data = []\n",
    "        \n",
    "        for db_name in configs.keys():\n",
    "            print(f\"   Testing {db_name}...\")\n",
    "            \n",
    "            query_times = []\n",
    "            \n",
    "            # Run multiple queries and measure time\n",
    "            for i in range(min(10, num_queries)):  # Test first 10 queries for speed\n",
    "                query_embedding = query_embeddings[i]\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                if db_name == \"chroma\":\n",
    "                    # Use the collection created during insertion benchmark\n",
    "                    pass  # Would need to maintain collection reference\n",
    "                elif db_name == \"qdrant\":\n",
    "                    # Similar for qdrant\n",
    "                    pass\n",
    "                elif db_name == \"faiss\":\n",
    "                    # FAISS search\n",
    "                    normalized_query = query_embedding / np.linalg.norm(query_embedding)\n",
    "                    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "                    normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "                    index.add(normalized_embeddings.astype('float32'))\n",
    "                    _, _ = index.search(normalized_query.reshape(1, -1).astype('float32'), 5)\n",
    "                \n",
    "                query_time = time.time() - start_time\n",
    "                query_times.append(query_time * 1000)  # Convert to ms\n",
    "            \n",
    "            # Calculate statistics\n",
    "            avg_query_time = np.mean(query_times) if query_times else 0\n",
    "            p95_query_time = np.percentile(query_times, 95) if query_times else 0\n",
    "            \n",
    "            performance_data.append({\n",
    "                'Database': db_name.title(),\n",
    "                'Documents': num_docs,\n",
    "                'Insertion Time (s)': insertion_times.get(db_name, 0),\n",
    "                'Docs/sec (insertion)': num_docs / insertion_times.get(db_name, 1),\n",
    "                'Avg Query Time (ms)': avg_query_time,\n",
    "                'P95 Query Time (ms)': p95_query_time,\n",
    "                'Queries/sec': 1000 / avg_query_time if avg_query_time > 0 else 0\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(performance_data)\n",
    "\n",
    "# Initialize performance optimizer\n",
    "optimizer = PerformanceOptimizer()\n",
    "print(\"âš¡ Performance Optimizer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run performance benchmark\n",
    "performance_results = optimizer.benchmark_query_performance(num_queries=50, num_docs=500)\n",
    "\n",
    "print(\"\\nðŸ“Š PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(performance_results.to_string(index=False, float_format='%.2f'))\n",
    "\n",
    "# Visualize performance results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Insertion performance\n",
    "ax1.bar(performance_results['Database'], performance_results['Docs/sec (insertion)'], \n",
    "        color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax1.set_title('Insertion Performance (Documents per Second)', fontweight='bold')\n",
    "ax1.set_ylabel('Documents/Second')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Query latency\n",
    "ax2.bar(performance_results['Database'], performance_results['Avg Query Time (ms)'], \n",
    "        color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax2.set_title('Average Query Latency', fontweight='bold')\n",
    "ax2.set_ylabel('Time (milliseconds)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Query throughput\n",
    "ax3.bar(performance_results['Database'], performance_results['Queries/sec'], \n",
    "        color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax3.set_title('Query Throughput (Queries per Second)', fontweight='bold')\n",
    "ax3.set_ylabel('Queries/Second')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# P95 latency\n",
    "ax4.bar(performance_results['Database'], performance_results['P95 Query Time (ms)'], \n",
    "        color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax4.set_title('P95 Query Latency', fontweight='bold')\n",
    "ax4.set_ylabel('Time (milliseconds)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Performance Insights:\")\n",
    "print(\"- FAISS typically offers the best raw performance for similarity search\")\n",
    "print(\"- Chroma provides good balance of features and performance for development\")\n",
    "print(\"- Qdrant excels in production scenarios with complex filtering requirements\")\n",
    "print(\"- Consider your specific use case: prototyping vs production, filtering needs, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Exercise 5: Metadata Schema Design Best Practices\n",
    "\n",
    "Let's explore effective metadata schema design for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataSchemaDesigner:\n",
    "    \"\"\"Design and validate metadata schemas for different use cases\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.schemas = {}\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    def create_schema(self, schema_name: str, schema_definition: Dict[str, Any]) -> None:\n",
    "        \"\"\"Create a metadata schema\"\"\"\n",
    "        self.schemas[schema_name] = schema_definition\n",
    "        print(f\"âœ… Created schema: {schema_name}\")\n",
    "    \n",
    "    def validate_document(self, document: Dict[str, Any], schema_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Validate a document against a schema\"\"\"\n",
    "        if schema_name not in self.schemas:\n",
    "            return {\"valid\": False, \"errors\": [f\"Schema {schema_name} not found\"]}\n",
    "        \n",
    "        schema = self.schemas[schema_name]\n",
    "        errors = []\n",
    "        \n",
    "        # Check required fields\n",
    "        required_fields = schema.get(\"required\", [])\n",
    "        for field in required_fields:\n",
    "            if field not in document.get(\"metadata\", {}):\n",
    "                errors.append(f\"Missing required field: {field}\")\n",
    "        \n",
    "        # Check field types\n",
    "        field_types = schema.get(\"properties\", {})\n",
    "        for field, expected_type in field_types.items():\n",
    "            if field in document.get(\"metadata\", {}):\n",
    "                value = document[\"metadata\"][field]\n",
    "                if expected_type == \"string\" and not isinstance(value, str):\n",
    "                    errors.append(f\"Field {field} should be string, got {type(value).__name__}\")\n",
    "                elif expected_type == \"number\" and not isinstance(value, (int, float)):\n",
    "                    errors.append(f\"Field {field} should be number, got {type(value).__name__}\")\n",
    "                elif expected_type == \"array\" and not isinstance(value, list):\n",
    "                    errors.append(f\"Field {field} should be array, got {type(value).__name__}\")\n",
    "        \n",
    "        return {\"valid\": len(errors) == 0, \"errors\": errors}\n",
    "    \n",
    "    def demonstrate_schemas(self) -> None:\n",
    "        \"\"\"Demonstrate different metadata schema patterns\"\"\"\n",
    "        print(\"ðŸ—ï¸ METADATA SCHEMA DESIGN PATTERNS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Schema 1: E-commerce Product Catalog\n",
    "        ecommerce_schema = {\n",
    "            \"name\": \"E-commerce Product Catalog\",\n",
    "            \"description\": \"Metadata for product descriptions and specifications\",\n",
    "            \"required\": [\"product_id\", \"category\", \"price\", \"availability\"],\n",
    "            \"properties\": {\n",
    "                \"product_id\": \"string\",\n",
    "                \"category\": \"string\",\n",
    "                \"subcategory\": \"string\",\n",
    "                \"brand\": \"string\",\n",
    "                \"price\": \"number\",\n",
    "                \"currency\": \"string\",\n",
    "                \"availability\": \"string\",\n",
    "                \"tags\": \"array\",\n",
    "                \"rating\": \"number\",\n",
    "                \"review_count\": \"number\",\n",
    "                \"launch_date\": \"string\",\n",
    "                \"is_featured\": \"boolean\"\n",
    "            },\n",
    "            \"filtering_strategy\": {\n",
    "                \"primary_filters\": [\"category\", \"price\", \"availability\", \"brand\"],\n",
    "                \"secondary_filters\": [\"rating\", \"tags\", \"is_featured\"],\n",
    "                \"range_filters\": [\"price\", \"rating\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Schema 2: Legal Document Management\n",
    "        legal_schema = {\n",
    "            \"name\": \"Legal Document Management\",\n",
    "            \"description\": \"Metadata for legal documents and contracts\",\n",
    "            \"required\": [\"document_type\", \"jurisdiction\", \"date_created\", \"classification\"],\n",
    "            \"properties\": {\n",
    "                \"document_type\": \"string\",\n",
    "                \"jurisdiction\": \"string\",\n",
    "                \"practice_area\": \"string\",\n",
    "                \"client_id\": \"string\",\n",
    "                \"matter_id\": \"string\",\n",
    "                \"date_created\": \"string\",\n",
    "                \"date_modified\": \"string\",\n",
    "                \"classification\": \"string\",\n",
    "                \"confidentiality_level\": \"string\",\n",
    "                \"parties\": \"array\",\n",
    "                \"contract_value\": \"number\",\n",
    "                \"expiry_date\": \"string\",\n",
    "                \"status\": \"string\"\n",
    "            },\n",
    "            \"filtering_strategy\": {\n",
    "                \"primary_filters\": [\"document_type\", \"jurisdiction\", \"practice_area\", \"classification\"],\n",
    "                \"secondary_filters\": [\"client_id\", \"status\", \"confidentiality_level\"],\n",
    "                \"date_filters\": [\"date_created\", \"date_modified\", \"expiry_date\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Schema 3: Research Paper Database\n",
    "        research_schema = {\n",
    "            \"name\": \"Research Paper Database\",\n",
    "            \"description\": \"Metadata for academic papers and research articles\",\n",
    "            \"required\": [\"title\", \"authors\", \"publication_date\", \"venue\"],\n",
    "            \"properties\": {\n",
    "                \"title\": \"string\",\n",
    "                \"authors\": \"array\",\n",
    "                \"publication_date\": \"string\",\n",
    "                \"venue\": \"string\",\n",
    "                \"venue_type\": \"string\",\n",
    "                \"doi\": \"string\",\n",
    "                \"arxiv_id\": \"string\",\n",
    "                \"fields_of_study\": \"array\",\n",
    "                \"keywords\": \"array\",\n",
    "                \"citation_count\": \"number\",\n",
    "                \"h_index\": \"number\",\n",
    "                \"impact_factor\": \"number\",\n",
    "                \"open_access\": \"boolean\",\n",
    "                \"funding_sources\": \"array\",\n",
    "                \"methodology\": \"string\"\n",
    "            },\n",
    "            \"filtering_strategy\": {\n",
    "                \"primary_filters\": [\"fields_of_study\", \"venue_type\", \"open_access\"],\n",
    "                \"secondary_filters\": [\"authors\", \"venue\", \"methodology\"],\n",
    "                \"range_filters\": [\"citation_count\", \"impact_factor\", \"publication_date\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Store schemas\n",
    "        self.create_schema(\"ecommerce\", ecommerce_schema)\n",
    "        self.create_schema(\"legal\", legal_schema)\n",
    "        self.create_schema(\"research\", research_schema)\n",
    "        \n",
    "        # Display schema summaries\n",
    "        for schema_name, schema in self.schemas.items():\n",
    "            print(f\"\\nðŸ“‹ {schema['name']}:\")\n",
    "            print(f\"   Description: {schema['description']}\")\n",
    "            print(f\"   Required fields: {', '.join(schema['required'])}\")\n",
    "            print(f\"   Total properties: {len(schema['properties'])}\")\n",
    "            print(f\"   Primary filters: {', '.join(schema['filtering_strategy']['primary_filters'])}\")\n",
    "    \n",
    "    def create_sample_documents(self) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"Create sample documents for each schema\"\"\"\n",
    "        samples = {\n",
    "            \"ecommerce\": [\n",
    "                {\n",
    "                    \"id\": \"prod_001\",\n",
    "                    \"text\": \"High-performance wireless noise-canceling headphones with 30-hour battery life and premium sound quality.\",\n",
    "                    \"metadata\": {\n",
    "                        \"product_id\": \"WH-1000XM5\",\n",
    "                        \"category\": \"Electronics\",\n",
    "                        \"subcategory\": \"Headphones\",\n",
    "                        \"brand\": \"Sony\",\n",
    "                        \"price\": 399.99,\n",
    "                        \"currency\": \"USD\",\n",
    "                        \"availability\": \"in_stock\",\n",
    "                        \"tags\": [\"wireless\", \"noise-canceling\", \"premium\"],\n",
    "                        \"rating\": 4.7,\n",
    "                        \"review_count\": 1250,\n",
    "                        \"launch_date\": \"2023-05-15\",\n",
    "                        \"is_featured\": True\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"prod_002\",\n",
    "                    \"text\": \"Ergonomic office chair with lumbar support and adjustable height for maximum comfort during long work sessions.\",\n",
    "                    \"metadata\": {\n",
    "                        \"product_id\": \"OFC-ERGO-2024\",\n",
    "                        \"category\": \"Furniture\",\n",
    "                        \"subcategory\": \"Office Chairs\",\n",
    "                        \"brand\": \"ErgoMax\",\n",
    "                        \"price\": 249.99,\n",
    "                        \"currency\": \"USD\",\n",
    "                        \"availability\": \"limited_stock\",\n",
    "                        \"tags\": [\"ergonomic\", \"office\", \"adjustable\"],\n",
    "                        \"rating\": 4.3,\n",
    "                        \"review_count\": 875,\n",
    "                        \"launch_date\": \"2024-01-10\",\n",
    "                        \"is_featured\": False\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"legal\": [\n",
    "                {\n",
    "                    \"id\": \"legal_001\",\n",
    "                    \"text\": \"Software licensing agreement between TechCorp and DataSoft for enterprise analytics platform usage.\",\n",
    "                    \"metadata\": {\n",
    "                        \"document_type\": \"License Agreement\",\n",
    "                        \"jurisdiction\": \"California\",\n",
    "                        \"practice_area\": \"Technology Law\",\n",
    "                        \"client_id\": \"CLIENT_001\",\n",
    "                        \"matter_id\": \"MAT_2024_001\",\n",
    "                        \"date_created\": \"2024-01-15\",\n",
    "                        \"date_modified\": \"2024-01-20\",\n",
    "                        \"classification\": \"Commercial\",\n",
    "                        \"confidentiality_level\": \"Confidential\",\n",
    "                        \"parties\": [\"TechCorp Inc.\", \"DataSoft LLC\"],\n",
    "                        \"contract_value\": 150000.00,\n",
    "                        \"expiry_date\": \"2026-01-15\",\n",
    "                        \"status\": \"Executed\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"research\": [\n",
    "                {\n",
    "                    \"id\": \"paper_001\",\n",
    "                    \"text\": \"A comprehensive study on transformer architectures for natural language processing tasks, comparing performance across multiple benchmarks.\",\n",
    "                    \"metadata\": {\n",
    "                        \"title\": \"Transformer Architectures for NLP: A Comprehensive Analysis\",\n",
    "                        \"authors\": [\"Dr. Jane Smith\", \"Prof. John Doe\", \"Dr. Alice Johnson\"],\n",
    "                        \"publication_date\": \"2024-03-15\",\n",
    "                        \"venue\": \"Journal of Machine Learning Research\",\n",
    "                        \"venue_type\": \"Journal\",\n",
    "                        \"doi\": \"10.1234/jmlr.2024.001\",\n",
    "                        \"arxiv_id\": \"2403.001234\",\n",
    "                        \"fields_of_study\": [\"Machine Learning\", \"Natural Language Processing\"],\n",
    "                        \"keywords\": [\"transformers\", \"attention\", \"NLP\", \"benchmarks\"],\n",
    "                        \"citation_count\": 45,\n",
    "                        \"h_index\": 12,\n",
    "                        \"impact_factor\": 3.8,\n",
    "                        \"open_access\": True,\n",
    "                        \"funding_sources\": [\"NSF\", \"Google Research\"],\n",
    "                        \"methodology\": \"Experimental\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return samples\n",
    "\n",
    "# Initialize metadata schema designer\n",
    "schema_designer = MetadataSchemaDesigner()\n",
    "schema_designer.demonstrate_schemas()\n",
    "\n",
    "print(\"\\nðŸ”§ Metadata Schema Designer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test schema validation\n",
    "print(\"\\nðŸ” SCHEMA VALIDATION TESTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sample_documents = schema_designer.create_sample_documents()\n",
    "\n",
    "# Test each document against its schema\n",
    "for schema_name, documents in sample_documents.items():\n",
    "    print(f\"\\nðŸ“‹ Testing {schema_name.title()} Schema:\")\n",
    "    \n",
    "    for doc in documents:\n",
    "        validation_result = schema_designer.validate_document(doc, schema_name)\n",
    "        \n",
    "        print(f\"   Document {doc['id']}: {'âœ… Valid' if validation_result['valid'] else 'âŒ Invalid'}\")\n",
    "        if not validation_result['valid']:\n",
    "            for error in validation_result['errors']:\n",
    "                print(f\"      - {error}\")\n",
    "\n",
    "# Test invalid document\n",
    "print(\"\\nðŸ§ª Testing Invalid Document:\")\n",
    "invalid_doc = {\n",
    "    \"id\": \"invalid_001\",\n",
    "    \"text\": \"This is an invalid document\",\n",
    "    \"metadata\": {\n",
    "        \"product_id\": \"INVALID\",\n",
    "        \"price\": \"not_a_number\",  # Should be number\n",
    "        # Missing required fields: category, availability\n",
    "    }\n",
    "}\n",
    "\n",
    "validation_result = schema_designer.validate_document(invalid_doc, \"ecommerce\")\n",
    "print(f\"   Invalid document: {'âœ… Valid' if validation_result['valid'] else 'âŒ Invalid'}\")\n",
    "for error in validation_result['errors']:\n",
    "    print(f\"      - {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate filtering strategies\n",
    "print(\"\\nðŸŽ¯ ADVANCED FILTERING STRATEGIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Set up vector store with sample documents\n",
    "filter_demo_store = AdvancedVectorStore(db_type=\"chroma\")\n",
    "\n",
    "# Add sample documents to vector store\n",
    "all_samples = []\n",
    "for schema_name, documents in sample_documents.items():\n",
    "    for doc in documents:\n",
    "        doc['metadata']['schema_type'] = schema_name\n",
    "        success = filter_demo_store.create_document(doc['id'], doc['text'], doc['metadata'])\n",
    "        if success:\n",
    "            all_samples.append(doc)\n",
    "\n",
    "print(f\"âœ… Added {len(all_samples)} documents to vector store\")\n",
    "\n",
    "# Demonstrate different filtering strategies\n",
    "filtering_examples = [\n",
    "    {\n",
    "        \"name\": \"Category Filtering\",\n",
    "        \"query\": \"high quality products\",\n",
    "        \"filters\": {\"category\": \"Electronics\"},\n",
    "        \"description\": \"Find electronics matching the query\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Schema Type Filtering\",\n",
    "        \"query\": \"research and analysis\",\n",
    "        \"filters\": {\"schema_type\": \"research\"},\n",
    "        \"description\": \"Find research documents only\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Brand Filtering\",\n",
    "        \"query\": \"premium audio equipment\",\n",
    "        \"filters\": {\"brand\": \"Sony\"},\n",
    "        \"description\": \"Find Sony products matching audio query\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Boolean Filtering\",\n",
    "        \"query\": \"featured products\",\n",
    "        \"filters\": {\"is_featured\": True},\n",
    "        \"description\": \"Find only featured products\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for example in filtering_examples:\n",
    "    print(f\"\\nðŸ” {example['name']}:\")\n",
    "    print(f\"   Description: {example['description']}\")\n",
    "    print(f\"   Query: '{example['query']}'\")\n",
    "    print(f\"   Filters: {example['filters']}\")\n",
    "    \n",
    "    results = filter_demo_store.search_with_filters(\n",
    "        example['query'], \n",
    "        filters=example['filters'], \n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"      {i+1}. {result['text'][:50]}... (score: {result['score']:.3f})\")\n",
    "            print(f\"          ID: {result['id']}, Schema: {result['metadata'].get('schema_type')}\")\n",
    "    else:\n",
    "        print(\"      No results found\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Filtering Best Practices:\")\n",
    "print(\"- Use primary filters for high-selectivity attributes (category, type, status)\")\n",
    "print(\"- Combine multiple filters to narrow down results effectively\")\n",
    "print(\"- Index frequently filtered fields for better performance\")\n",
    "print(\"- Consider hierarchical metadata for complex organizational structures\")\n",
    "print(\"- Use range filters for numerical and date fields when appropriate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "From this module, you should now understand:\n",
    "\n",
    "### âŒ Traditional Database Limitations:\n",
    "1. **No semantic search**: Traditional databases can't understand meaning or similarity\n",
    "2. **Inefficient high-dimensional indexing**: B-tree indexes don't work well for vectors\n",
    "3. **Linear scan performance**: Similarity search requires checking every record\n",
    "4. **No approximate algorithms**: Can't trade accuracy for speed in similarity search\n",
    "\n",
    "### âœ… Vector Database Advantages:\n",
    "1. **Optimized for similarity search**: Purpose-built for finding similar vectors quickly\n",
    "2. **Approximate Nearest Neighbor algorithms**: HNSW, IVF, LSH for fast retrieval\n",
    "3. **Metadata filtering**: Combine semantic similarity with traditional filters\n",
    "4. **Horizontal scaling**: Built for production workloads with millions of vectors\n",
    "\n",
    "### ðŸ—ï¸ Database Selection Criteria:\n",
    "1. **Development vs Production**: Chroma for prototyping, Pinecone/Qdrant for production\n",
    "2. **Cost considerations**: FAISS (free) vs Pinecone (premium) vs Qdrant (middle ground)\n",
    "3. **Feature requirements**: Advanced filtering, hybrid search, multi-tenancy\n",
    "4. **Performance needs**: Query latency, insertion speed, concurrent users\n",
    "\n",
    "### ðŸ“Š CRUD Operations:\n",
    "1. **Create**: Efficient batch insertion with metadata\n",
    "2. **Read**: Retrieve documents by ID or similarity\n",
    "3. **Update**: Modify text content and metadata\n",
    "4. **Delete**: Remove documents and clean up indexes\n",
    "\n",
    "### ðŸŽ¯ Metadata Design Patterns:\n",
    "1. **Schema-based approach**: Define required fields and data types\n",
    "2. **Hierarchical organization**: Use nested metadata for complex structures\n",
    "3. **Filtering strategy**: Primary filters for high-selectivity, secondary for refinement\n",
    "4. **Performance optimization**: Index frequently filtered fields\n",
    "\n",
    "## ðŸ”„ Vector Database Workflow:\n",
    "1. **Schema Design** â†’ 2. **Document Ingestion** â†’ 3. **Index Building** â†’ 4. **Query Processing** â†’ 5. **Results Filtering**\n",
    "\n",
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "In the next modules, we'll explore:\n",
    "- **Module 7**: Indexing algorithms and performance optimization\n",
    "- **Module 8**: Comparing different search methods (exact, approximate, hybrid)\n",
    "- **Module 9**: Advanced retrieval strategies and re-ranking\n",
    "\n",
    "Understanding vector databases is crucial for building production-ready RAG systems that can scale to millions of documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Discussion Questions\n",
    "\n",
    "1. When would you choose a local vector database like Chroma vs a cloud solution like Pinecone?\n",
    "2. How would you design a metadata schema for a multi-tenant SaaS application?\n",
    "3. What are the trade-offs between exact and approximate similarity search?\n",
    "4. How would you handle updates to documents in a production vector database?\n",
    "5. What factors should influence your choice of similarity metric?\n",
    "\n",
    "## ðŸ“ Optional Exercises\n",
    "\n",
    "1. **Performance Comparison**: Set up Pinecone or Weaviate cloud instances and compare with local databases\n",
    "2. **Custom Metadata Schema**: Design a metadata schema for your domain (e.g., medical records, financial documents)\n",
    "3. **Batch Operations**: Implement efficient batch insertion and update operations\n",
    "4. **Monitoring and Metrics**: Add performance monitoring to track query latency and throughput\n",
    "5. **Hybrid Search**: Combine vector similarity with traditional keyword search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}